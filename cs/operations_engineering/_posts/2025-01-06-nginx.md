---
title: docker로 nginx 설정하기
excerpt: nginx 까먹지 않기 위한 기록
---

<br/>

- 이번에 private vpc 구축을 다시하면서 서버들을 새로 만들었다  
  이번에는 Nginx 도 도커로 돌리고, docker network 도 host 모드를 사용했다   
  인프라 작업은 정말 어지럽다  
  그래서 덕분에 docker 삽질 많이해서 도움이 된거같다...  
  아는만큼 보이고 재미있는 법이지 그래서 처음엔 진짜 재미없었음 ㅎ 이제는 자신감좀 생김          
  - 제일 많이쓴 명령어는 `docker logs -f test_api`     
    로그야 고마워  

<br/>

## Nginx

### Worker process
CPU 코어 1개당 하나의 Worker Process 가 생성되고 작업을 수행함   

- 그러면 몇개가 좋을까?
  - 물리적인 CPU 코어 개수만큼 할당하는것이 이상적
    - nginx.conf 에서 auto 를 지정해주면 자동으로 CPU 코어 개수에 알맞게 생성해줌      
  - 각 코어는 서로 process 를 공유하지 않음 -> 모든 코어당 1개의 worker process 를 사용하면 전체 서버의 리소스를 최대로 사용하는 셈
  - 무작정 많이 할당하면 오히려 자원만 낭비하고 성능저하 문제까지 일으킬 수 있음

<br/>

### Connection 허용 개수
각 Worker Process 별 최대 허용 커넥션 개수 default : 1024개     
(요거를 왜 알아봤냐면 TPS test 하는데 요청수를 너무 못받는데 서버는 아무 이상 없길래 알아본)   

- ulimit -n :: CPU 코어의 connection 허용수 확인 명령어
- worker connection 변수 값은 event content 안에 작성

  => 최대 Request 동시 처리 수는?  
  Worker Process 개수 * 4096 요청을 동시 처리할 수 있게됨   

<br/>

### worker_rlimit_nofile   
Worker Process 가 최대로 열 수 있는 파일수에 대한 제한 설정 -> 처리량을 늘려주는 것 

```
worker_process auto;
worker_rlimit_nofile 65535

events {
        worker_connections 4096;
}

http {
...
```

<br/>

### http 블록 
nginx로 들어오는 web traffic에 대한 처리 방법과 방향을 설정해주는 블록 = client 와 nginx 사이     
(요거를 왜 알아봤냐면 내가 막 http 블록 안에 upstream 명령어 쓰고 그랬음 무지의..)   

- keepalive
  - client-server 간에 지속적인 연결을 유지하도록 해주는 기능   
  - HTTP는 기본적으로 요청-응답 후 연결을 끊는 방식(비연결형 프로토콜)이지만, keepalive를 사용하면 하나의 TCP 연결을 여러 요청에 재사용 가능  
  - 이는 연결 설정/해제에 드는 비용(TCP handshake, 해제 과정)을 줄여 성능을 크게 향상시킴   

<br/>

- reset_timeout_connection
  - server 가 응답하지 않는 client에 대한 connection을 닫을 수 있도록 허용하는 옵션
 
<br/>

- send_timeout
  - client 에 response 전송 시 제한된 시간
  - 응답이 없거나 느린 client를 제한하는 것
  - 지정한 시간 안에 client 가 아무것도 받지 못하면 connection 닫힘
  - default 60초   

<br/>

- client_header_timeout
  - request 의 header 정보 읽을 때 제한된 시간
  - 지정한 시간안에 client 가 header 전송 안하면 요청은 408(Request Time-out)로 끝남
  - default 60초
- client_body_timeout
  - request 의 bidy 정보 읽을 때 제한된 시간
  - default 60초

<br/>

- proxy_send_timeout
  - proxied server 로 요청 전송 시 제한된 시간
- proxy_read_timeout
  - proxied server 로부터 응답을 읽을 때 제한된 시간
  - 두개의 연속적인 읽기 작업 사이의 timeout (전체 응답 전송 timeout x)
  - 지정한 시간안에 proxied server 가 아무것도 전송 안하면 connection 닫힘
  - default 60초

<br/>

- sendfile
  - nginx에서 정적파일을 보내도록 설정하는 것 (sendfile on)

<br/>

- tcp_nopush
  - client 로 패킷 전송되기 전 buffer 가 가득찼는지 확인 -> 다찼으면 패킷 전송하도록 함 => 네트워크 오버헤드 줄이도록 설정하는 것
- tcp_nodelay
  - 소켓이 패킷 크기에 상관없이 buffer에 데이터를 보내도록 함

<br/>

### upstream 블록
nginx가 로드 밸런싱할 backend server 그룹 정의      
nginx가 proxy 역할을 할 때, client 요청을 특정 backend server로 전달해야 하는데, 이때 다수의 백엔드 서버가 있다면 로드 밸런싱이 필요함   
upstream 블록에서 이 서버 그룹을 정의하고, Nginx는 해당 그룹 내 서버들로 요청을 분산시킴   

<br/>

= Nginx는 클라이언트로부터 받은 요청을 proxy_pass로 정의된 upstream 서버로 전달함   

```
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    least_conn;  # 최소 연결 수 알고리즘 사용
}

server {
    listen 80;
    server_name example.com;

    location / {
        proxy_pass http://backend;
    }
}
```

=> http, upstream 블록이 함께 동작하여 client 요청을 받아 적절한 backend server로 분산시키고 응답을 반환하는 것이 Nginx의 기본 구조    

<br/><br/>

## Nginx 설정

### Nginx 에 Reverse Proxy 설정 추가
- /nginx/conf.d 의 service-url.conf 파일 생성
  
  ```
  upstream container_name { server loclhost:9001 }
  ```

  - upstream 명령어는 nginx server 블록 안에 위치할 수 없음, http 블록에서 사용불가하니까

- Nginx 설정 파일(/nginx/nginx.conf)의 include 경로 체크하기 

  ```
  ...
  
  include /etc/nginx/conf.d/*.conf;
  
  ...
  ```

- /nginx/sites-enabled 의 default 파일에 추가

  ```
  server {
          listen 80;
          listen [::]:80;
          server_name domain.test.com;

          location / {
                  proxy_pass http://test_api;
                  ...
  ```

<br/>

### Reverse Proxy
- client 가 요청한 데이터를 대신 처리하여 백엔드 서버와 통신하고, 그 결과를 client 에게 전달하는 서버 = 백엔드 서버와 직접 통신하지 못하도록 설정     
- nginx 에서 proxy_pass 를 사용하는 경우 = reverse proxy 설정하는 작업

<br/>

- 동작방식

1. client가 web server(nginx) 에 요청을 보냄 :: ex) `http://ttaehee.test.com`
2. nginx 가 해당 요청을 내부적으로 다른 서버(백엔드 서버)로 전달함 :: ex) `proxy_pass http://test_api;`
3. 백엔드 서버에서 응답 처리 후, nginx 가 그 결과를 다시 client 에게 전달

<br/>

- 장점
  - 보안 강화 :: 백엔드 서버의 ip, port 숨길 수 있음
  - 로드 밸런싱 :: 여러 백엔드 서버로 요청 분산 가능
  - 캐싱 :: nginx에서 결과를 캐싱해 성능 향상
  - SSL 처리 :: HTTPS 요청을 nginx 가 처리하고, 백엔드 서버는 HTTP 만 사용해도 됨     

<br/>

- 참고) Forward Proxy
  - client와 server 간의 요청을 대리하는 방식
  - client를 숨기고 외부 서버와 통신하도록 함
  - ex) 회사에서 특정 웹사이트 접근을 제한하기 위해 proxy server를 사용

<br/><br/>

Reference  
- [Nginx documentation](https://nginx.org/en/docs/)
- [테코톡) nginx](https://youtu.be/6FAwAXXj5N0?si=bBYgrNFo8Okqb18T)
